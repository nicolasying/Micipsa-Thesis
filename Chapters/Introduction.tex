\chapter{Introduction} 

\label{chap:introduction} 

%----------------------------------------------------------------------------------------
\section{Semantic Memory, Representation and Processing} 

Semantics as in linguistic context, is the connection between language forms such as orthography and syntax to lexical or phrasal meanings. The brain processes semantics largely with semantic memory \parencite{tulvingEpisodicSemanticMemory1972}, which loci in human cognition system are still actively being debated. 

Semantic memory is unlike episodic memory, which is individually specific and modality dependent. As semantic memory is associated with general world knowledge \parencite{mcraeSemanticMemory2013}, semantic memory tends to be shared across individuals within a common cultural background. Such invariance provides a window for semantic memory loci localization in the human brain. 

In Tulving's view, semantic memory is conceptually dissociated, but not necessarily functionally or structurally separated from procedural and episodic memory. However, studies \parencite{vargha-khademDifferentialEffectsEarly1997} suggest the structural and functional dissociation of episodic memory and semantic memory, and that parahippocamal cortices, as a classical theoretical locus of episodic memory, are not crucial for the normal functioning of semantic memory.

\begin{table}
\caption{Involvement of Cerebral Areas in Semantic Tasks}
\label{tab:distributedareastudysynthesis}
\centering

\begin{tabularx}{\textwidth}{@{} L *{5}{X} @{}}
\toprule
\tabhead{Reference} & \tabhead{Frontal Lobe} & \tabhead{Temporal Lobe} & \tabhead{Parietal Lobe} & \tabhead{Occipital Lobe} & \tabhead{Limbic Lobe}\\
\midrule
\cite{tsukiuraDissociableRolesBilateral2006} & IFG & CA, STG & AG & GF & PCG \\
{[}TODO More{]} &  &  &  &  &  \\
\bottomrule \\
\end{tabularx}
\end{table}
    

While some theorist argue for the temporal localization of semantic memory [TODO ref], recent studies found neural correlates of semantic knowledge distributed in multiple lobes (refer to Table \ref{tab:distributedareastudysynthesis} for a resume), supporting thus the distributed hypothesis that semantic knowledge might be encoded in all brain areas. The cortices involved in semantic processing other than the temporal cortex, are strongly associated to perceptual, sensorial and affectual processings, suggesting that semantic memory depends on episodic events. [TODO, REF, e.g. premotor and sensorimotor cortex on verb]

A theoretical reconciliation between these two schools is the specialization of cortical areas implicated in semantic tasks: the abstract, amodal semantic memory being grounded by concrete modal episodic memories \parencite{pecherGroundingCognitionRole2005}. 

The classical semantic memory locus could serve as the convergence zone for binding information from modality-specific cortices \parencite{damasioNeuralBasisLexical1996, damasioNeuralSystemsWord2004, simmonsSimilarityintopographyPrincipleReconciling2003}. Anatomical evidences, that the possible loci sit at convergences of multiple perceptual processing streams \parencite{binderNeurobiologySemanticMemory2011}, support this theory. \cite{pattersonWhereYouKnow2007} further exploited Damasio et al's arguments by proposing the \emph{Hub-and-Spoke} model, where a semantic hub, not only acts as a pointer and a information-binder, but also constructs, refines semantic concepts and builds cross-modal similarity structures using episodic event. In parallel, \cite{paivioMindItsEvolution2008} argued for a dual-coding system to address the problem of representing abstract concepts which do not necessarily have perceptual input: in addition to accumulated perceptual information for concrete concepts, a more meta-semantic department keeps record for all concepts. 

Multiple theories exist to account for the contribution of other cortical areas in semantic memory system. Feature-based distributional models argue that those cortices are recruited to encode modality-specific information, which participate in completing the semantic representation. [TODO Reference, ralphNeuralComputationalBases2017 p11] Domain-specific distributional models \parencite{mahonWhatDrivesOrganization2011} use the category-specific pathology studies to argue for a local tuning of semantic topics due to cortical functional connectivity differentiation [TOOD rephrase ]. \emph{Controlled Semantic Cognition} \parencite{ralphNeuralComputationalBases2017} system argues for an functional [TODO word choice] rather than representational account. CSC considers the neural correlates in non-hub areas as the interaction with semantic representation system and the computation of semantic entities such as combination and selection, which is modulated by linguistic or task contexts. \dots

% On adopting \cite{eggertWernickeWorksAphasia1977}'s \emph{embodied semantics} proposal, the Hub-and-Spoke model assumes the core role of language and non-verbal experiences when acquiring and updating concept knowledges, which are stored in modality/property-specific cortical areas (such as color, motion), defined as \emph{spokes}. A mediating transmodal semantic hub is to communicate the modality-dependent information sources, and is argued to be located in the ATL region, concluded from a meta-analysis of studies on semantic processing in human brain, using a variety of imaging methods and task settings. Linguistic, non-linguistic tasks with auditory and visual stimuli, along with generative tasks, all converge to show that bilateral ATL are recruited in object naming, recognition, reading and speech comprehension.

In this project, we restrain the discussion to lexicosemantic system, particularly we will focus on the representation and processing of word meanings in an ecological auditive experiment. 

\section{Syntagmatic and Paradigmatic Axes in Linguistics}

\cite{jakobsonFundamentalsLanguage1963} and \cite{desaussureCoursLinguistiqueGenerale1969} Propose that all linguistic units are arranged in two modes which are \emph{combination} and \emph{selection}, or \emph{syntagm} and \emph{paradigm}. \emph{Combination} is in \emph{presentia} as the linguistic unit (in the current context, a lexicon) is contextualized by other elements presented in a linguistic sequence. \emph{Selection} is in \emph{absentia} as it is linked to other alternative substitutions which are absent from the current context. 

Jakobson further further illustrated the twofold character of language via selection-deficient and contexture-deficient aphasics using data from \cite{goldsteinLanguageLanguageDisturbances1948, headAphasiaKindredDisorders1920, hughlingsjacksonAffectionsSpeechDisease1879}ï¼Œ bridging formal linguistic works with psycholinguistic studies.  [TODO REF 102-106 ralphNeuralComputationalBases2017 for more pathological studies]

Similarity disorder (selection-deficiency) patients are able to complete scraps of words or sentence, but are unable to uncontextualize themselves, thus unable to utter ''it rains'' unless it rains actually. The retrieval of the most precise lexicon is blocked, and the internal relation between concepts are dissolved. For those patients, an isolated word means nothing, occurrences of one same words in different contexts are homonyms, and the production of word tends to be bound by other associative words (for example, \emph{knife} are referred to as \emph{pencil-sharpener}, \emph{bread-knife} and \emph{knife-and-fork}) or metonymies (\emph{fork} for \emph{knife}, \emph{eat} for \emph{toaster}), or replaced by the most general terms such as \emph{chose} and \emph{machin} in French. The utterances are highly dominated by spatial, temporal and usage proximities, which are not necessarily parallel to similarity. They also lose the ability to switch register and stay in their idiolect reality. As remarked by Jakobson, for such an aphasic whose substitutional capacity has been disabled and contextual capacity intact, the emissive and receptive linguistic competence relies solely on contiguity. 

Contiguity disorder (contexture-deficiency) patients, on the other hand, are impaired to propositionize, inflect and desolve compound words such as \emph{thanksgiving} into \emph{thanks} and \emph{giving}. They produce agramtical sentences as a chaotic word heap. The approximative identifications of a presented concept are quasimetaphoric (such as \emph{spyglass} are produced for \emph{microscope}, \emph{fire} for \emph{gaslight}), without any deliberate transfer of meaning as it is in the case of poetry and rhetorics. 

We relate de Saussure and Jakobson's twofold structuralism to neuro-psycholinguistic theories on semantic processing. The paradigmatic axis being associated with semantic similarity relations, and syntagmatic axis with semantic control or episodic-event based semantic information comparisons. Two parallel (not necessarily separate) systems handle respectively associational and metaphorical retrieval and access of words in linguistic tasks.

This project implements tentatives to rebuild lexical semantic relations projected onto these two axes. For the potential differences of definition, we use different names, and align \emph{semantic similarity} with the paradigmatic axis, and \emph{semantic association} with the syntagmatic axis.

%----------------------------------------------------------------------------------------

\section{Computational Semantic Representation Modeling}

Natural language processing and understanding in general artificial intelligence has partially branched away from cognitive computational linguistic works. [TODO more details] We restrain computational semantic modeling to the models attempting replications of human linguistic dynamics. 

Semantic representation models digitalize the natural language word meanings into numeric representations that can be understood and processed by neural networks and computer systems. There are two schools of modeling, symbolic and distributional models.

\subsection{Symbolic Relational Semantic Models}

\label{subsection:symbolicembedding}
Classical semantic models assumes the meanings are organized as an indexable binary feature array \parencite{smithSemanticMemoryPsychological1974} or interconnected nodes in a large semantic graph-like ontological network \parencite{collinsRetrievalTimeSemantic1969}. Depending on the implementation, such symbolic structures are usually abstracted or independent from episodic, perceptual experiences and are able to account for abstract conceptual comparisons, thus modeling mainly paradigmatic similarities. 

Modern implementation of such models still rely largely on human manual coding. WordNet-alike \parencite{millerWordNetLexicalDatabase1995, millerWordNetElectronicLexical1998, sagotBuildingFreeFrench2008, pradetWonefImprovedExpanded2014} knowledge bases are examples of semantic networks which encodes inter-word semantic relations. In this class of models, lexicons are regrouped into \emph{synsets}, forming synonymy sets, each representing one different meaning of the lexicon. Synsets are interconnected with relations such as \emph{antonymy, hyponymy, hypernymy, meronymy, toponymy}\dots

\subsection{Statistical Distributional Representations}

\label{subsection:statisticalembedding}

\cite{harrisDistributionalStructure1954}'s distributional hypothesis argues that ''linguistics items with similar distributions have similar meanings.'' Most statistical models based on this theoretical foundation could be classified into latent semantic inference models \parencite{deerwesterUnitedStatesPatent1989, penningtonGloveGlobalVectors2014} and hyperspace analogue to language models \parencite{burgessHyperspaceAnalogueLanguage1995, mikolovLinguisticRegularitiesContinuous, }[TODO REF syntax dependent encoding]. As they make heavy use of contextual information, the syntagmatic information are retained by those classes of models.

Such representation models use high dimensional vectors to encode semantic entities. Similarity measures are derived on vector distance metrics including cosine distance, gaussian distance and Minkowski distances. Models such as \cite{penningtonGloveGlobalVectors2014, mikolovLinguisticRegularitiesContinuous} achieve adequate performance on similarity benchmarks. 

On the linguistic nature of distributional representation models, \cite{lapesaContrastingSyntagmaticParadigmatic2014} tested combinations of different hyper-parameters of co-occurrence based representation building algorithm. They used behavioral priming data on syntagmatic and paradigmatic word-pairs to contrast parameters' influence on two axes' performance. The results showed that larger context window size produce embeddings in favor of syntagmatic relations, and small context window size for paradigmatic relations. Additionally, models always yield a mixture of two axes information. [TODO, window size = 4 for eg. ]

%----------------------------------------------------------------------------------------

\section{Semantic Neural Encoding/Decoding Experiments}

Historically, to identify the specific functions of various cortical areas involved in semantic processing, neuroscientists had to rely on semantic deficits and lesion studies. With cognitive modeling development, neuroimaging techniques enables examinations of various model proposal without having to open the skull. 

[TODO, redundancy of the next paragraph?]
David Marr proposed in 1982 the three levels of modeling in \parencite{marrVisionComputationalInvestigation1982}: \emph{computation, algorithm} and \emph{implementation}. On operating on the computational level, cognitive modelers either try to replicate the temporal-spatial dynamics of cerebral activities, thus \emph{encodes} neural signals, and/or use measured signals to recover external stimuli, thus \emph{decodes} brain activity. 

Given the temporal and spatial resolution constraints of neuroimaging techniques among electroencephalography (EEG), magnetoencephalography (MEG), functional magnetic resonance imaging (fMRI), positron emission tomography (PET), fMRI and PET gained enormous popularity in the semantic field. fMRI gives a much better spatial resolution than EEG up to millimeters, but it is generally poor in temporal resolution. Classic semantic stimuli units are presented at sub-second level (hundreds of milliseconds) but the usual imaging frequency is at second level, and the measured blood-oxygen-level dependent (BOLD) signal approximates a temporal convolution of real brain activation and hemodynamic function over 4 ~ 7 seconds. [TODO MEG, Justification of fMRI]

Encoding and decoding experiments heavily rely on computational semantic representational models, especially distributional representations. \cite{mitchellPredictingHumanBrain2008} used contextual co-occurrence vectors to encode semantic processing activities for concrete nouns. The predictive model showed significant generalization power. 

\subsection{Multi-Network Participation in Semantic Processing}

A large amount of literatures with encoding and decoding experiments report results in favor of distributed semantic processings in the human brain. 

\cite{mitchellPredictingHumanBrain2008}'s concrete noun encoding experiments reported the most accurately predicted voxels to be located in IFC, parieto-temporal regions. \cite{pereiraUniversalDecoderLinguistic2018} used fMRI signals to decode lexical and phrasal semantic stimuli presented in isolation. Among the 5000 most informative voxels of each subject, functional networks in human brain other than the linguistic one take a significant portion consistently across subjects. 

Experiments conducted with ecological stimuli found consistent results. [TODO Rephrase] \parencite{todorovicAnalysesIRMfLors2018, verdierEncodageActiviteNeuronale2018}.

\subsection{Evidences for Domain-based Distribution}
[TODO Resume of the following works]

\parencite{huthContinuousSemanticSpace2012, huthNaturalSpeechReveals2016, mahonWhatDrivesOrganization2011, damasioNeuralBasisLexical1996, damasioNeuralSystemsWord2004}

\subsection{Evidences for Feature-based Distribution}

[TODO Resume of the following works]
\cite{borghesaniWordMeaningVentral2016}
\cite{rowtulaDeepAutoencoderNearPerfect2018} mixed textual semantic embeddings and image-based semantic embeddings to encode \cite{pereiraUniversalDecoderLinguistic2018}'s data. The multimodal encoding model, compared to purely textual encoding model, gave much better results in fMRI signal correlation.

[TODO 2nd deg refs of Patterson, ]

\subsection{Evidences for Semantic Control Networks}

[TODO]
\cite{ralphNeuralComputationalBases2017}
%----------------------------------------------------------------------------------------

\section{Outline}

This master's project attempts to examine different cortical regions' participation in the two semantic processing axes, namely paradigmatic and syntagmatic. We attribute each axis, or organisational principle, with a fine-tuned semantic representation model, configured with our assumptions and hypotheses on these axes. 
Through an fMRI encoding experiment using lexical semantic models in an ecological setting, we infer each region's functional properties based on the locally preferred organisational principle.

In chapter \ref{chap:hypotheses}, along with the tested hypotheses, assumptions on paradigmatic and syntagmatic axes and semantic distributional representation structures are presented and discussed. In chapter \ref{chap:methods}, we will present our methods on building semantic representations, preliminary validations of assumptions, fMRI encoding settings and interpretation of results. Then the obtained results are discussed in chapter \ref{chap:results}. We will present further ad-hoc analyses and possible implications of our results in chapter \ref{chap:discussions}.